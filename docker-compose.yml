version: "3.9"

x-airflow-common: &airflow-common
  image: job_warehouse_discord:latest
  restart: unless-stopped
  environment:
    - LOAD_EX=n
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW_HOME=/opt/airflow
    - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_AIRFLOW}
    - DB_HOST=${DB_HOST}
    - DB_USER=${DB_USER}
    - DB_PASSWORD=${DB_PASSWORD}
    - DB_NAME=${DB_AIRFLOW}
    - AIRFLOW_WEBSERVER_SECRET_KEY=${AIRFLOW_WEBSERVER_SECRET_KEY}
    - DBT_TARGET=airflow
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/config/airflow.cfg:/opt/airflow/airflow.cfg
    - ./airflow/entrypoint/entrypoint_airflow.sh:/opt/airflow/entrypoint.sh
    - ./airflow/scripts:/opt/airflow/scripts
    - ./airflow/tasks:/opt/airflow/tasks
    - ./airflow/dbt:/opt/airflow/dbt
    - ./.env:/opt/airflow/.env
  networks:
    - discord_network

services:
  postgresql_db:
    image: postgres:latest
    container_name: postgresql_db
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=${DB_AIRFLOW}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/01_create_db.sql
      - ./db/init_schema_tables.sql:/docker-entrypoint-initdb.d/02_create_schema_tables.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_AIRFLOW}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - discord_network

  webserver:
    <<: *airflow-common
    container_name: airflow-webserver
    depends_on:
      postgresql_db:
        condition: service_healthy
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    entrypoint: ["/opt/airflow/entrypoint.sh"]
    command: webserver
    logging:
      options:
        max-size: "10m"
        max-file: "3"

  airflow_scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    depends_on:
      webserver:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob"]
      interval: 30s
      timeout: 30s
      retries: 5
    command: airflow scheduler

networks:
  discord_network:
    driver: bridge

volumes:
  postgres_data:
