[core]
dags_folder = /opt/airflow/dags
executor = LocalExecutor
load_examples = False
parallelism = 32
max_active_tasks_per_dag = 16
dagbag_import_timeout = 30
task_runner = StandardTaskRunner
default_timezone = utc
min_file_process_interval = 30

[database]
sql_alchemy_conn = postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:5432/${DB_NAME}
sql_engine_encoding = utf-8
sql_alchemy_pool_size = 10
sql_alchemy_pool_recycle = 1800
sql_alchemy_max_overflow = 20
sql_alchemy_reconnect_timeout = 300
sql_alchemy_connect_args.keepalives_idle = 60

[webserver]
base_url = http://localhost:8080
web_server_host = 0.0.0.0
web_server_port = 8080
web_server_worker_timeout = 120
secret_key = ${AIRFLOW_WEBSERVER_SECRET_KEY}
workers = 4
worker_class = sync
access_logfile = -
error_logfile = -
expose_config = False
auth_backends = airflow.providers.google.auth.backend.google_auth
dag_default_view = grid
dag_orientation = LR
demo_mode = False
statsd_on = False

[scheduler]
job_heartbeat_sec = 5
scheduler_heartbeat_sec = 10
min_file_process_interval = 30
dag_dir_list_interval = 300
print_stats_interval = 30
child_process_log_directory = /opt/airflow/logs/scheduler
dag_run_conf_overrides_params = True

[smtp]
smtp_host = localhost
smtp_starttls = True
smtp_ssl = False
smtp_port = 25
smtp_mail_from = airflow@example.com