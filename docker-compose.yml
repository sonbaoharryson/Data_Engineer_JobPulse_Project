version: "3.9"

x-airflow-common: &airflow-common
  image: job_warehouse_discord:latest
  restart: unless-stopped
  environment: &airflow-common-env
    AIRFLOW_HOME: /opt/airflow
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor # Using CeleryExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_AIRFLOW}
    AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_AIRFLOW}
    AIRFLOW__CELERY__WORKER_CONCURRENCY: 2
    AIRFLOW__CELERY__WORKER_PREFETCH_MULTIPLIER: 1
    AIRFLOW__CELERY__TASK_ACKS_LATE: "True"
    AIRFLOW__CORE__FERNET_KEY: ""
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_WEBSERVER_SECRET_KEY}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW_CONFIG: "/opt/airflow/config/airflow.cfg"
    AIRFLOW_CONN_TRINO_DEFAULT: trino://trino@trino:8080/default
    DBT_TARGET: airflow
    DB_HOST: ${DB_HOST}
    DB_PORT: ${DB_PORT}
    DB_USER: ${DB_USER}
    DB_PASSWORD: ${DB_PASSWORD}
    DB_NAME: ${DB_AIRFLOW}
  volumes:
    - ./airflow/dags:/opt/airflow/dags
    - ./airflow/config/airflow.cfg:/opt/airflow/config/airflow.cfg
    - ./airflow/entrypoint/entrypoint_airflow.sh:/opt/airflow/entrypoint.sh
    - ./airflow/scripts:/opt/airflow/scripts
    - ./airflow/tasks:/opt/airflow/tasks
    - ./airflow/dbt:/opt/airflow/dbt
    - ./.env:/opt/airflow/.env
  depends_on: &airflow-common-depends-on
    redis:
      condition: service_healthy
    postgresql_db:
      condition: service_healthy
  # networks:
  #   - discord_network

services:
  postgresql_db:
    image: postgres:16.4 # unchanged from your file
    container_name: postgresql_db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_AIRFLOW}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgresql/init_db/init.sql:/docker-entrypoint-initdb.d/01_create_db.sql
      - ./postgresql/init_schema_table/init_schema_tables.sql:/docker-entrypoint-initdb.d/02_create_schema_tables_job_db.sql
      - ./postgresql/init_wh_catalog/init_catalog_tables.sql:/docker-entrypoint-initdb.d/03_create_catalog_tables_trino.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_AIRFLOW}"]
      interval: 10s
      timeout: 5s
      retries: 5
    # networks:
    #   - discord_network

  redis:
    image: redis:latest
    container_name: redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 30s
      retries: 50
      start_period: 30s

  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    depends_on:
      <<: *airflow-common-depends-on
    environment:
      <<: *airflow-common-env
    entrypoint: ["/opt/airflow/entrypoint.sh"]
    restart: "no"

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow-webserver
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 60s
      timeout: 30s
      retries: 5

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
      airflow-webserver:
        condition: service_healthy
    command: scheduler
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"',
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  airflow-worker:
    <<: *airflow-common
    command: celery worker --celery-hostname=%h
    environment:
      <<: *airflow-common-env
      # Required to handle warm shutdown of the celery workers properly
      # See https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation
      DUMB_INIT_SETSID: "0"
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
      airflow-webserver:
        condition: service_healthy
    healthcheck:
      # yamllint disable rule:line-length
      test:
        - "CMD-SHELL"
        - 'celery --app airflow.providers.celery.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}" || celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      replicas: 2 # Number of worker replicas to run, increase this to create multiple worker containers allowing more parallel task execution
    mem_swappiness: 0 # Disable swap to prevent slowdowns
    restart: always

  object-store:
    image: minio/minio
    container_name: object-store
    environment:
      MINIO_ROOT_USER: ${MINIO_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_PASSWORD}
    command: ["server", "/data", "--console-address", ":9001"]
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    # networks:
    #   - discord_network

  minio-init:
    image: minio/mc
    container_name: minio-init
    depends_on:
      object-store:
        condition: service_started
    entrypoint: >
      /bin/sh -c "
      until mc alias set minio http://object-store:9000 ${MINIO_USER} ${MINIO_PASSWORD}; do
        sleep 2;
      done;
      mc mb -p minio/warehouse || true;
      mc mb -p minio/crawled-data || true;
      echo 'MinIO initialization completed';
      "
    # networks:
    #   - discord_network

  trino:
    image: trinodb/trino:latest
    container_name: trino
    depends_on:
      minio-init:
        condition: service_completed_successfully
      postgresql_db:
        condition: service_healthy
    env_file:
      - .env
    environment:
      POSTGRES_HOST: ${DB_HOST}
      POSTGRES_PORT: ${DB_PORT}
      POSTGRES_DB: ${DB_TRINO}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      MINIO_USER: ${MINIO_USER}
      MINIO_PASSWORD: ${MINIO_PASSWORD}
    ports:
      - "8081:8080"
    volumes:
      - ./trino/catalog:/etc/trino/catalog
    # networks:
    #   - discord_network

  trino-init:
    image: trinodb/trino:latest
    container_name: trino-init
    depends_on:
      trino:
        condition: service_started
      postgresql_db:
        condition: service_healthy
    volumes:
      - ./trino/init_schema:/init_schema
    entrypoint: >
      /bin/sh -c "
      echo 'Waiting for Trino...';
      until trino --server http://trino:8080 --execute 'SELECT 1'; do
        sleep 3;
      done;

      echo 'Running init_schema.sql';
      trino --server http://trino:8080 --file /init_schema/init_schema.sql;
      echo 'Init schema completed';
      "
    restart: "no"
# networks:
#   discord_network:
#     driver: bridge

volumes:
  postgres_data:
  minio_data:
